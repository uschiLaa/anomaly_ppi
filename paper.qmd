---
title: "Is this normal? A new projection pursuit index to assess a sample against a multivariate null distribution"
author: 
  - name: Annalisa Calvi
    affiliations:
      name: Monash University
      department: School of Mathematics
  - name: Ursula Laa
    affiliations:
      name: University of Natural Resources and Life Sciences, Vienna
      department: Institute of Statistics
    email: ursula.laa@boku.ac.at
    ORCID: 0000-0002-0249-6439
  - name: Dianne Cook
    affiliations:
      name: Monash University
      department: Department of Econometrics and Business Statistics
    email: dicook@monash.edu
    ORCID: 0000-0002-3813-7155
format:
  jasa-pdf:
    keep-tex: true    
abstract: |
  Many data problems contain some reference or normal conditions, upon which to compare newly collected data. This scenario occurs in data collected as part of clinical trials to detect adverse events, and or for measuring climate change against historical norms. The data is typically multivariate, and often the normal ranges are specified by a multivariate normal distribution. The work presented in this paper develops methods to compare the new sample against the reference distribution with high-dimensional visualisation. It uses a projection pursuit guided tour to produce a sequence of low-dimensional projections steered towards those where the new sample is most different from the reference. A new projection pursuit index is defined, and the drawing of the projected ellipse is computed analytically. The methods are implemented in the R package, `tourr`. 
keywords:
  - exploratory data analysis
  - statistical graphics
  - dimension reduction
  - high-dimensional visualisation
  - climate change
  - clinical trials
bibliography: bibliography.bib  
header-includes: | 
  \usepackage{amsmath}
  \usepackage{amsthm}
  \usepackage{float}
  \usepackage{hyperref}
  \usepackage[utf8]{inputenc}
  \usepackage{bm}
  \def\tightlist{}
  \usepackage{setspace}
  \newcommand\pD{$p\text{-}D$}
  \newcommand\kD{$k\text{-}D$}
  \newcommand\dD{$d\text{-}D$}
  \newcommand\gD{$2\text{-}D$}
  \newtheorem*{theorem}{Theorem}
---

```{r include=FALSE}
# Set up chunk for for knitr
knitr::opts_chunk$set(
  fig.width = 5,
  fig.height = 5,
  fig.align = "center",
  out.width = "100%",
  code.line.numbers = FALSE,
  fig.retina = 4,
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE
)
```

```{r}
#| label: load-libraries
#| warning: false
#| echo: false
library(tourr)
library(mulgar)
library(dplyr)
library(ggplot2)
library(patchwork)
library(knitr)
library(kableExtra)
library(mvtnorm)
```

```{r}
#| label: plot-theme
theme_set(theme_linedraw() +
   theme(
     aspect.ratio = 1,
     plot.background = element_rect(fill = 'transparent', colour = NA),
     plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
     panel.background = element_rect(fill = 'transparent', 
                                     colour = NA),
     panel.grid.major = element_blank(), 
     panel.grid.minor = element_blank(), 
     axis.title.x = element_blank(), axis.title.y = element_blank(),
     axis.text.x = element_blank(), axis.ticks.x = element_blank(),
     axis.text.y = element_blank(), axis.ticks.y = element_blank(),
     legend.background = element_rect(fill = 'transparent', 
                                      colour = NA),
     legend.key = element_rect(fill = 'transparent', 
                               colour = NA),
     legend.position = "bottom", 
     legend.title = element_blank(), 
     legend.text = element_text(size=4),
     legend.key.height = unit(0.25, 'cm'),
     legend.key.width = unit(0.25, 'cm')
   )
)
interior_annotation <- function(label, position = c(0.92, 0.92)) {
  annotation_custom(grid::textGrob(label = label,
      x = unit(position[1], "npc"), y = unit(position[2], "npc"),
      gp = grid::gpar(cex = 1, col="grey70")))
}
```

## Introduction

Linear projections are useful in many aspects of statistical analysis of multivariate data, and especially useful for visualising the data. A linear projection provides a dimension reduction while maintaining interpretability. For example, a biplot [@Ga71;@GH96] shows the structure creating the maximum variance in the data, and also visualizing the projection matrix to learn which variables contribute to it. We might find clusters of outliers that were hiding in high dimensions.

More generally, projection pursuit [@FT74;@JS87;@Hu85] defines a quantitative criterion for the interestingness of a projection (a projection pursuit index), and searches the space of possible projections for the most interesting one to display. We can also define sequences of interpolated linear projections to better understand a multivariate distribution. Animating a randomly selected interpolated sequence of linear projections is called a grand tour [@As85;@BA86b;@BCAH05;@CLBW06;@tours2022]. The combination of these two approaches would then use a projection pursuit index to select interesting projections, but display them via an interpolated path to provide context. This is called a guided tour [@cook1995].

The question is whether we can use these techniques to assess new data samples in the context of an established normal, such as a specific multivariate normal distribution. In physics, the normal distribution may describe experimental results, or a global fit for a selected model, and we might want to compare to a set of other models. In medical applications, the normal distribution might summarize historic data of a healthy population and we compare it to samples from new patients. In outlier detection we might use robust measures to define the normal distribution and look for anomalies. 

This paper describes a new projection pursuit index which is optimized by projections where a new sample is most distant from the existing normal distribution. It is organised as follows. @sec-background provides more context for the methods and visualisation. @sec-anomaly-index provides the details of the new index, and example use is illustrated in @sec-examples. 

## Background {#sec-background}

To compare a new sample with an existing norm, like a multivariate normal distribution, in higher than two dimensions, we have typically used two samples of points. The norm is represented by points on the surface of a $p$-dimensional ellipsoid, corresponding to a confidence level. A sample of points uniformly distributed on a $p$-dimensional sphere is generated by 

1. Simulating a sample of observations ($\mathbfit{x}$, which are \pD{} vectors)
from $N_p(\mathbfit{\mu}, \Sigma)$. 
2. Transforming each observation to have unit distance from the mean, $\frac{\mathbfit{x}^\top}{||\mathbfit{x}^\top||}$. 
To convert this to points on the surface of a confidence ellipsoid, 

3. transform the shape using a specific variance covariance, and shift to center on the mean vector. 

Finally, new observations can be visually compared with this ellipsoid by 

4. plotting them together. 

@fig-ci illustrates this process for \gD. This is easiest way to view this normal region relative to a new sample for any \pD{} problem. 

```{r}
#| echo: false
#| label: fig-ci
#| fig-width: 8
#| fig-height: 2
#| fig-cap: "Simulating a uniform sample on a sphere involves sampling from a multivariate normal (a) and transforming each observation to have length equal to 1. A confidence ellipsoid is generated by transforming the sphere relative to a specified variance-covariance matrix (c), and new observations can be visually assessed to be inside or outside by plotting with the ellipsoid (d)."
set.seed(717)
d1 <- matrix(rnorm(716 * 2), ncol = 2) 
d2 <- t(apply(d1, 1, geozoo:::l2norm_vec))
vc <- matrix(c(1, -0.5, -0.5, 1), ncol=2, byrow=TRUE)
evc <- eigen(vc)
vc2 <- (evc$vectors) %*% diag(sqrt(evc$values)) %*% t(evc$vectors)
d3 <- d2 %*% vc2 |>
  as.data.frame()

d4 <- d3 |>
  bind_rows(data.frame(V1=0.6, V2=0.6)) |>
  bind_rows(data.frame(V1=0.3, V2=0.3)) |>
  mutate(type = c(rep("ci", nrow(d3)), "in", "out"))

d1 <- as.data.frame(d1)
d2 <- as.data.frame(d2)
d3 <- as.data.frame(d3)

p1 <- ggplot(d1, aes(x=V1, y=V2)) +
  geom_point(alpha=0.5) +
  xlab(expression(x[1])) +
  ylab(expression(x[2])) +
  xlim(c(-3.2, 3.2)) +
  ylim(c(-3.2, 3.2)) +
  interior_annotation("a") +
  #ggtitle("a. Bivariate standard normal sample") +
  theme(axis.text = element_blank())

p2 <- ggplot(d2, aes(x=V1, y=V2)) +
  geom_point(alpha=0.5) +
  xlab(expression(x[1])) +
  ylab(expression(x[2])) +
  xlim(c(-1.2, 1.2)) +
  ylim(c(-1.2, 1.2)) +
  interior_annotation("b") +
  #ggtitle("b. Uniform on a sphere") +
  theme(axis.text = element_blank())

p3 <- ggplot(d3, aes(x=V1, y=V2)) +
  geom_point(alpha=0.5) +
  xlab(expression(x[1])) +
  ylab(expression(x[2])) +
  xlim(c(-1.2, 1.2)) +
  ylim(c(-1.2, 1.2)) +
  interior_annotation("c") +
  #ggtitle("c. Points on surface of confidence ellipsoid.") +
  theme(axis.text = element_blank())

p4 <- ggplot(d4, aes(x=V1, y=V2, shape=type)) +
  geom_point(alpha=0.5) +
  xlab(expression(x[1])) +
  ylab(expression(x[2])) +
  xlim(c(-1.2, 1.2)) +
  ylim(c(-1.2, 1.2)) +
  interior_annotation("d") +
  #ggtitle("d. Observations inside and outside confidence ellipsoid.") +
  theme(legend.position = "none", 
        axis.text = element_blank())
  
p1 + p2 + p3 + p4 + plot_layout(ncol=4)
```

For example, @fig-compare compares a new sample of patient scores against the normal range represented by an ellipse (a) and also against a simulated sample of normal patients (b). While these are useful approaches, the ragged edges of the projected ellipse make it difficult to compare the new sample precisely agains the normal ranges.

```{r}
#| eval: false
#| echo: false
liver_stats <- tribble(
  ~ALT, ~AST, ~ALP, ~albumin, ~bilirubin, ~GGT, ~protein, ~sex, ~stat,
  5,     5,   30,      35,        0,    2, 60,   "m", "mn",
  40,     30,  120,      50,        20,   44, 80,   "m", "mx",
  5,     5,   30,      35,        0,    2, 60,   "f", "mn",
  40,     30,  120,      50,        20,   70, 80,    "f", "mx"
)
set.seed(1158)
norm_vc <- diag(1, 4, 4)
norm_vc[upper.tri(norm_vc) == TRUE] <- sample(c(0.3, 0.4, 0.5), 6, replace=T)
for (i in 1:3)
  for (j in (i+1):4)
    norm_vc[j, i] <- norm_vc[i, j]
colnames(norm_vc) <- c("GGT", "AST", "ALP", "ALT")
norm_samp <- rmvnorm(500, sigma=as.matrix(norm_vc))
colnames(norm_samp) <- c("GGT", "AST", "ALP", "ALT")
norm_samp <- as.data.frame(norm_samp)
norm_ci <- gen_vc_ellipse(norm_vc) * 2
colnames(norm_ci) <- c("GGT", "AST", "ALP", "ALT")
norm_ci <- as.data.frame(norm_ci)

set.seed(217)
women_vc <- norm_vc
women_vc[1,4] <- 0.5
women_vc[4,1] <- 0.5
women <- rmvnorm(16, mean=c(0.3, -0.3, -1.2, -1.5),
                 sigma = women_vc)
colnames(women) <- c("GGT", "AST", "ALP", "ALT")
women <- as.data.frame(women)

norm_plus <- bind_rows(norm_samp, women)
norm_plus <- norm_plus |>
  mutate(type = factor(c(rep("norm", 500), rep("samp", 16))))
animate_xy(norm_plus[,1:4], col=norm_plus$type)

norm_ci_plus <- bind_rows(norm_ci, women)
norm_ci_plus <- norm_ci_plus |>
  mutate(type = factor(c(rep("ci", 500), rep("samp", 16))))
animate_xy(norm_ci_plus[,1:4], col=norm_ci_plus$type)

```

::: {#fig-compare layout-ncol=2}

![Relative to confidence ellipse.](images/example1.png){#fig-compare1 width=250 align="center"}
 
![Relative to normal patients.](images/example2.png){#fig-compare width=250 align="center"}

Illustration of current procedure: (a) compare new sample with points of the surface of a $p\text{-}D$ ellipse, (b) compare new sample with a simulated sample of normal patients. Although both approaches are useful, the rough edges of the projected ellipse points makes it difficult to precisely assess the positions of the new sample against the normal bounds.
:::

Although this is flexible, this does not make it easy to guide the tour towards the directions (projections) where the samples are most different from the normal. What would be desirable is to analytically define the confidence ellipsoid, compute flag observations that are outside, steer the tour to projections that reveal the extent of the difference. And also display the projected ellipsoid as a geometric shape rather than a sample of points. These are the procedures that are described in the next section.  

## Anomaly index {#sec-anomaly-index}

### Projecting an ellipsoid

A \pD{} ellipsoid corresponding to a given variance-covariance ($\Sigma$) is defined by 

$$
(\mathbfit{x}-\mathbfit{\mu}) \Sigma^{-1}(\mathbfit{x}-\mathbfit{\mu})^T = c^2
$$
where $c$ a constant that depends on a specific confidence level.

\begin{theorem}
  The projection of this \pD{} ellipsoid in \gD{} has the equation
$$(\mathbfit{y} - \mathbfit{\mu}_p)(P^T \Sigma P)^{-1}(\mathbfit{y} - \mathbfit{\mu}_p)^T = c^2.$$
\end{theorem}
\begin{proof}
The projection of an ellipsoid onto \gD{} is an ellipse, where the curve of the ellipse is defined through the set of points $\mathbfit{x}$ for which the gradient is parallel to the projection plane. That is, the curve 
consists of $\mathbfit{x}$ satisfying

$$\nabla (\mathbfit{x}-\mathbfit{\mu}) \Sigma^{-1}(\mathbfit{x}-\mathbfit{\mu})^T = 2 (\mathbfit{x}-\mathbfit{\mu}) \Sigma^{-1} = 2\mathbfit{s}P^T
$$

for some $\mathbfit{s} \in \mathbb{R}^2$, where $P$ is a $(p\times 2)$ orthonormal basis defining the
projection. We can write $\mathbfit{x}-\mathbfit{\mu} = \mathbfit{s} P^T \Sigma$.
Making this substitution in the \pD{} ellipsoid equation yields

$$c^2 = (\mathbfit{x}-\mathbfit{\mu}) \Sigma^{-1}(\mathbfit{x}-\mathbfit{\mu})^T = \mathbfit{s} P^T \Sigma P \mathbfit{s}^T
$$

We call points in the projection that are on the curve $\mathbfit{y}$, so that $\mathbfit{y} = \mathbfit{x}P$ for $\mathbfit{x}$ on the \pD{} curve. Then $\mathbfit{y} - \mathbfit{\mu}_p = (\mathbfit{x} - \mathbfit{\mu})P = \mathbfit{s} P^T \Sigma P$, where $\mathbfit{\mu}_p = \mathbfit{\mu} P$ is the projected mean. We then substitute $(\mathbfit{y} - \mathbfit{\mu}_p) (P^T \Sigma P)^{-1}$ for $\mathbfit{s}$ in the equation \(c^2 = \mathbfit{s} P^T \Sigma P \mathbfit{s}^T\). From this we can compute the analog equation for the projection as

$$(\mathbfit{y} - \mathbfit{\mu}_p)(P^T \Sigma P)^{-1}(\mathbfit{y} - \mathbfit{\mu}_p)^T = c^2$$

as claimed.
\end{proof}

This means the matrix $(P^T \Sigma P)^{-1}$ is defining the ellipse in the \gD{} projection. In general $c$ could be any constant, but typically we would select it as a quantile of the $\chi^2$ distribution, so that the size of the ellipse corresponds to a selected probability.

<IMAGES OF PROJECTED ELLIPSE>

### Index specification

To define a measure of an interesting projection is to maximize the average Mahahlanobis distance [@mahalanobis] in the projection for a subset of points, $W$. The set of points could be chosen in different ways, but the default is those that are outside the specified ellipsoid in \pD{}. Alternatives could be to select a set of observations with the largest Mahalanobis distance, manually select observations or possibly a group of points identified via clustering of the extremes.

The index is written as

$$
\sum_{\mathbfit{w} \in W} (\mathbfit{w} - \mathbfit{\mu}) P (P^T\Sigma P)^{-1}P^T(\mathbfit{w} - \mathbfit{\mu})^T
$$

where by default $W = \{\mathbfit{x}: (\mathbfit{x}-\mathbfit{\mu}) \Sigma^{-1}(\mathbfit{x}-\mathbfit{\mu})^T > c^2\}$, is the set of observations outside the \pD{} ellipsoid.

### Additional considerations

If the observations in $W$ are primarily departing from the normal range in the same direction, the index will be expected to perform well in finding this average direction. However, if the observations have very different departures from the norm, it may be useful to break them into groups, and separately optimize on these subsets. One could consider clustering these observations using angular distance to find groups of observations that have similar directions of departure.

## Implementation

This is implemented in the `tourr` [@tourr;@tourr-cran] package, where the projected ellipsoid can be drawn for each projection. The guided tour will take arguments specifying the data, and the null variance-covariance matrix. 

```{r}
#| eval: false
#| echo: true
library(tourr)
library(mulgar)
set.seed(929)
vc_null <- matrix(rep(0.5, 5*5), ncol=5)
diag(vc_null) <- 1
m_null <- rep(0, 5)
vc_samp <- matrix(rep(0, 5*5), ncol=5)
diag(vc_samp) <- 1
vc_samp[4,5] <- -0.47
vc_samp[5,4] <- -0.56
vc_samp <- vc_samp*0.1
m_samp <- c(0, 0, 0, 1.9, 2.3)
samp <- as.data.frame(rmvn(6, 
                           mn = m_samp, 
                           vc = vc_samp))
animate_xy(samp, guided_anomaly_tour(anomaly_index(),
  ellipse=vc_null), ellipse=vc_null, 
  axes = "bottomleft", half_range=5, center=FALSE)
```

::: {#fig-anomaly layout-ncol=2}

![Random projection](images/anomaly1.png){#fig-anomaly1 width=300 align="center"}
 
![Optimal projection](images/anomaly2.png){#fig-anomaly2 width=300 align="center"}

Two projections of simulated example data corresponding to the sample code: (a) random projection where sample is inside the 2-D ellipse, (b) optimal projection from index, showing most of the sample outside. A red cross indicates that the point is outside the p-D ellipse. The optimal projection uses mostly variables $x_4, x_5$, which is expected because these are the two directions where the sample most differs from the norm.
:::

## Examples {#sec-examples}

### Health: liver function tests

This example is motivated by a problem posed during consulting with a pharmaceutical company, but the data shown here is simulated, simply to illustrate the application. Liver function tests commonly provide measurements on albumin, protein, bilirubin, gamma-glutamyl- transferase (GGT), aspartate aminotransferase (AST), alkaline phosphatase (ALP) and alanine aminotransferase (ALT). There are normal ranges on these measurements reported by @lib-med-liver-norms and listed in @tbl-liver-norms. 

```{r}
#| label: tbl-liver-norms
#| tbl-cap: "Normal ranges provided for liver function tests."
liver_stats <- tribble(
  ~ALT, ~AST, ~ALP, ~albumin, ~bilirubin, ~GGT, ~protein, ~sex, ~stat,
  5,     5,   30,      35,        0,    2, 60,   "m", "min",
  40,     30,  120,      50,        20,   44, 80,   "m", "max",
  5,     5,   30,      35,        0,    2, 60,   "f", "min",
  40,     30,  120,      50,        20,   70, 80,    "f", "max"
)
liver_stats |> 
  filter(sex == "m") |>
  select(-sex) |>
  select(stat, albumin, protein, bilirubin, GGT, AST, ALP, ALT) |>
  kable(
    row.names = FALSE,
    col.names = c("", "albumin (g/L)", "protein (g/L)", 
        "bilirubin (µmol/L)", "GGT (IU/L)", "AST (IU/L)", 
        "ALP (IU/L)", "ALT (IU/L)"),
    booktabs = TRUE
  )
```

These measurements are also likely correlated, based on guidance like the *ratio of AST to ALT of 2:1 indicates possible alcohol abuse*. Although this was provided by the pharmaceutical company, correlation between these measurements for normal patients is not readily available. When a correlation matrix for normal patients is provided this would allow construction of the null ellipse upon which to examine new samples.

```{r}
#| eval: false
#| echo: false
animate_xy(women,            
           ellipse=norm_vc, 
           axes = "bottomleft", 
           half_range=5, 
           center=FALSE)
  
animate_xy(women, guided_anomaly_tour(anomaly_index(),
                                    ellipse=norm_vc), 
           ellipse=norm_vc, 
           axes = "bottomleft", 
           half_range=5, 
           center=FALSE)
  
set.seed(1208)
pt1 <- tibble(GGT = rnorm(5, mean=1.3, sd=0.15),
              AST = rnorm(5, mean=1, sd=0.2),
              ALP = c(1, 1.3, 1.6, 2.8, 2.9), 
              ALT = c(-1, -1.3, -1.6, -2.9, -3.1))
animate_xy(pt1, guided_anomaly_tour(anomaly_index(),
                                     ellipse=norm_vc), 
           ellipse=norm_vc, 
           axes = "bottomleft", 
           half_range=5, 
           center=FALSE,
           edges = matrix(c(1:4, 2:5), byrow=FALSE, ncol=2),
           obs_labels = c("45", "50", "55", "65", "70"))
```

@fig-liver illustrates two examples. The first is similar to the consulting project. A sample of liver test scores for new patients was provided in order to examine their values relative to the normal range. Here only four tests are used, GGT, AST, ALP, ALT. Plot (a) shows a projection of this sample relative to the normal range. Three of the patients are outside the confidence ellipse but all of the patients are located away from the mean. What has been typical in the past is to compute normal values based on tests of healthy young males. The samples provided for the project were all recorded on women. We see that this sample has slightly lower ALT and ALP, which is consistent with what is reported in @lib-med-liver-norms.

The second example shows a longitudinal record of a single patient, measured at ages 45, 50, 55, 65 and 70. The lines connect the records in tome order. The projection corresponds to the maxima from a projection-pursuit guided tour using the anomaly index:

$$
P = \left[ \begin{array}{rr}
            0.371 & -0.128 \\
            -0.388 & 0.732 \\
            0.140 & 0.599 \\
            -0.832 & -0.297 
            \end{array} \right]
$$

From the axes representation in @fig-liver (b) of this projection, we can see that the direction that profile extends is primarily contrasting ALT (fourth row) and ALP (third row). This is consistent with aging, where ALP increases and ALT decreases. 

::: {#fig-liver layout-ncol=2}

![Sample of female patients](images/liver1.png){#fig-liver1 width=300 align="center"}
 
![Longitudinal profile of an aging patient](images/liver2.png){#fig-liver2 width=300 align="center"}

Two projections of simulated example data corresponding to common liver tests: (a) sample of female patients, (b) longitudinal test results for a single patient. Red cross indicates observation is outide the 4-D confidence ellipse. The female patients tend to have lower ALP and ALT than the normal range. As the patient aged, the level of ALP increases and ALT decreases.
:::

### Robust statistics: weather extremes

This example is motivated by the weather data example from @filzmoser2018. We illustrate using the anomaly index to  compare potential outliers with a reference normal distribution that is derived using robust methods on the original data. The data contains 16 numerical measurements that are averages across the three summer months June, July and August, reported for 68 years (1955 - 2022) (see @filzmoser2018 for more details).

To estimate the underlying normal distribution the data is first centered and scaled using the median and the median absolute deviation (MAD), before applying the minimum covariance determinant (MCD) estimator [@rousseeuw1985multivariate] using the implementation in @robustbase. The MCD estimates for the mean vector and the variance-covariance matrix are then used to define the reference normal distribution.

Here we will consider points to be outlying if they are more than $5 \sigma$ away from that mean value. With $p=16$ this corresponds to a Mahalanobis distance of $60$ or larger. This will identify $20$ out of the $68$ observations as outlying. Since these are outlying in different combinations of variables, as found in @filzmoser2018, we will further separate the outlying points into clusters based on  similarity in direction. The similarity is computed by first normalizing observations to have length $1$ and then apply k-means clustering with Euclidean distance. The cluster validation statistics computed using @fpc suggest that $k=4$ or $k=5$ is reasonable, so for simplicity we will work with $k=4$.

The new anomaly index is first applied to the full dataset, such that the final projection will be affected by averaging distance of points in many directions. It provides a global picture showing where the outlying points differ from the normal distribution.

```{r}
#| eval: false
#| echo: false
library(ShapleyOutlier)
library(robustHD)
library(tidyverse)
library(tourr)
library(fpc)

data("WeatherVienna")
# first part of the code is preprocessing
# this is following the vignette from the package
# see https://cran.r-project.org/web/packages/ShapleyOutlier/vignettes/ShapleyOutlier_examples.html
weather_summer <- WeatherVienna |> dplyr::select(-c(`t`, t_max, t_min, p_max, p_min)) |>
  drop_na() |>
  filter(month %in% c("JUN", "JUL", "AUG")) |>
  filter(year >= 1955) |>
  group_by(year) |>
  dplyr::select(-month) |>
  summarise(across(.cols = everything(), function(x) mean(x)))

X <- weather_summer |> dplyr::select(-c(num_frost, num_ice, year))
rownames(X) <- weather_summer$year
#> Warning: Setting row names on a tibble is deprecated.
X <- robStandardize(X)

set.seed(1)
MCD <- covMcd(X, alpha = 0.5, nsamp = "best")
#> Warning in .fastmcd(x, h, nsamp, nmini, kmini, trace = as.integer(trace)): 'nsamp = "best"' allows maximally 100000 subsets;
#> computing these subsets of size 17 out of 68
mu <-MCD$center
Sigma <- MCD$cov

###### preprocessing done
# this is now our own code to work with these inputs

# start with finding outlying points and clustering
size_weather <- qchisq(2*pnorm(5)-1, ncol(X))
dist_pd <- mahalanobis(X, mu, Sigma)
X_outside <- X[dist_pd > size_weather,]
X_outside_scaled <- t(apply(X_outside, 1,
                    function(x) (x)/sqrt(sum(x^2))))
for(k in 2:6){
  set.seed(150)
  X_km <- kmeans(X_outside_scaled, k)
  cs <- cluster.stats(dist(X_outside_scaled), X_km$cluster)
  print(cs$dunn)
}

#preferred solution 5 clusters using dunn/dunn2 index
set.seed(150)
X_km <- kmeans(X_outside_scaled, 5)
# making a vector that labels all points
# use 0 to indicate point is not an outlier
cluster_labels_all <- as_tibble(X,
                               rownames = "year") |>
  left_join(as_tibble(X_km$cluster,
                              rownames = "year")) |>
  mutate(cluster = if_else(is.na(value), 0, value)) |>
  arrange(cluster)
cluster_labels <- factor(cluster_labels_all$cluster,
                         levels = c(1:5, 0))

X_sorted <- cluster_labels_all |>
  select(-year, -cluster, -value) |>
  rename(atmax = avg_t_max,
         atmin = avg_t_min,
         nsumm = num_summer,
         nheat = num_heat,
         sunh = sun_h,
         nclear = num_clear,
         ncloud = num_cloud,
         rh = rel_hum,
         rhmax = rel_hum_max,
         rhmin = rel_hum_min,
         vwind = wind_v,
         vw60 = num_wind_v60,
         vwmax = wind_v_max,
         prec = precp_sum,
         nprec = num_precp_01)

set.seed(22)
animate_xy(as.matrix(X_sorted), 
           guided_anomaly_tour(anomaly_index(),
                               ellipse=as.matrix(Sigma),
                               ellc = size_weather,
                               ellmu = mu), 
           ellipse=as.matrix(Sigma), ellc = size_weather,
           ellmu = mu, cex=2, 
           axes="bottomleft",
           col = as.factor(cluster_labels),
           palette = "Purple-Yellow",
           center = FALSE, rescale = FALSE,
           ellmarks = FALSE, axislablong = TRUE)


# color codes
# "#80146E" "#7262B2" "#31A0C2" "#5ECBBB" "#B9E5B9"
# "#F5F2D8"
# wait for getting random starting planes for
# better results
set.seed(55)
animate_xy(X_sorted[cluster_labels == 4,], 
           guided_anomaly_tour(anomaly_index(),
                               ellipse=as.matrix(Sigma),
                               ellc = size_weather,
                               ellmu = mu), 
           ellipse=as.matrix(Sigma), ellc = size_weather,
           ellmu = mu,
           axes="bottomleft",
           col = "#5ECBBB", half_range = 7, cex = 2,
           center = FALSE, rescale = FALSE,
           ellmarks = FALSE, axislablong = TRUE)

# extract final view, draw with new axis display that
# only labels longer arrows, draw without red X

# cluster 4 only has two points, they are more in
# the center when optimizing for all outliers
# next step: check optimization for only cluster 4
# also cluster 3 might be of interest, it appears
# somewhat spread out in the final view, but it is
# also the largest cluster

```

::: {#fig-weather layout-ncol=2}

![All outlying points clustered](images/weather1.png){#fig-weather1 width=300 align="center"}
 
![Only cluster 4](images/weather2.png){#fig-weather2 width=300 align="center"}


Examining weather anomalies using projections identified by the anomaly index: (a) computed on all outlying points, (b) computed only for cluster 4. In (a) the outlying points are somewhat orthogonal to the normal ellipse, which is primarily using the temperature min (`atmn`) and max (`atmx`) variables. In (b) the two observations are primarily extreme in the minimum temperature (`atmn`) variable, and have lower than normal minima.
:::

XXX SOMETHING ON WHAT THIS MEANS RELATIVE TO THE ORIGINAL EXAMPLE

## Conclusion

Say something about the relationship with @directional-outlyingness and Stahel-Donoho outlyingness. This method could be implemented in the way we used to show ellipses, generate points on the surface of the irregular shape, overlay the data on this and make projections.

Difference from general outlier detection, see use of Mahalanobis distance in @filzmoser2018.

Potential new directions.


